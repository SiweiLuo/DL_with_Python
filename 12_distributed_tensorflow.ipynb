{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_distributed_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiweiLuo/DL_with_Python/blob/master/12_distributed_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIOM718DMN79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import os \n",
        "\n",
        "def reset_graph(seed=42):\n",
        "  tf.reset_default_graph()\n",
        "  tf.set_random_seed(seed)\n",
        "  np.random.seed(seed) \n",
        "  \n",
        "%matplotlib inline \n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"distributed\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpDrzFBPMntC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "c = tf.constant(\"Hello distributed Tensorflow\") \n",
        "server = tf.train.Server.create_local_server() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a3bqI9UMxj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c3120d1-5e3e-4b92-8678-641826c6e103"
      },
      "source": [
        "with tf.Session(server.target) as sess: \n",
        "  print(sess.run(c)) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello distributed Tensorflow'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfvL8KTMM4W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_spec = tf.train.ClusterSpec({\n",
        "    \"ps\":[\n",
        "        \"127.0.0.1:2221\",  # /job:ps/task:0\n",
        "        \"127.0.0.1:2222\",  # /job:ps/task:1\n",
        "    ],\n",
        "    \"worker\": [\n",
        "        \"127.0.0.1:2223\",  # /job:worker/task:0\n",
        "        \"127.0.0.1:2224\",  # /job:worker/task:1\n",
        "        \"127.0.0.1:2225\",  # /job:worker/task:2\n",
        "    ]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDAk8oxfNCTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_ps0 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=0)\n",
        "task_ps1 = tf.train.Server(cluster_spec, job_name=\"ps\", task_index=1)\n",
        "task_worker0 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=0)\n",
        "task_worker1 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=1)\n",
        "task_worker2 = tf.train.Server(cluster_spec, job_name=\"worker\", task_index=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYv7lvNIws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph() \n",
        "\n",
        "with tf.device(\"/job:ps\"):\n",
        "    a = tf.Variable(1.0, name=\"a\")\n",
        "\n",
        "with tf.device(\"/job:worker\"):\n",
        "    b = a + 2\n",
        "\n",
        "with tf.device(\"/job:worker/task:1\"):\n",
        "    c = a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwkjLnPgNOlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d35c0fd4-16ef-4c19-aef5-4cdf22cdfbb5"
      },
      "source": [
        "with tf.Session(\"grpc://127.0.0.1:2221\") as sess:\n",
        "    sess.run(a.initializer)\n",
        "    print(c.eval())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdU6rxCeNRKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "with tf.device(tf.train.replica_device_setter(\n",
        "        ps_tasks=2,\n",
        "        ps_device=\"/job:ps\",\n",
        "        worker_device=\"/job:worker\")):\n",
        "    v1 = tf.Variable(1.0, name=\"v1\")  # pinned to /job:ps/task:0 (defaults to /cpu:0)\n",
        "    v2 = tf.Variable(2.0, name=\"v2\")  # pinned to /job:ps/task:1 (defaults to /cpu:0)\n",
        "    v3 = tf.Variable(3.0, name=\"v3\")  # pinned to /job:ps/task:0 (defaults to /cpu:0)\n",
        "    s = v1 + v2            # pinned to /job:worker (defaults to task:0/cpu:0)\n",
        "    with tf.device(\"/task:1\"):\n",
        "        p1 = 2 * s         # pinned to /job:worker/task:1 (defaults to /cpu:0)\n",
        "        with tf.device(\"/cpu:0\"):\n",
        "            p2 = 3 * s     # pinned to /job:worker/task:1/cpu:0\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.log_device_placement = True\n",
        "\n",
        "with tf.Session(\"grpc://127.0.0.1:2221\", config=config) as sess:\n",
        "    v1.initializer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX7nnZPHNUBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiypKaZlNYmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4cf0323-0825-4fde-c84d-7d5d3e2f1613"
      },
      "source": [
        "default1 = tf.constant([5.])\n",
        "default2 = tf.constant([6])\n",
        "default3 = tf.constant([7])\n",
        "dec = tf.decode_csv(tf.constant(\"1.,,44\"),\n",
        "                    record_defaults=[default1, default2, default3])\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(dec))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 6, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSFwQ0nwNchn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "7718eca7-90ff-42a1-d8e9-27bf904e1b5c"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "test_csv = open(\"my_test.csv\", \"w\")\n",
        "test_csv.write(\"x1, x2 , target\\n\")\n",
        "test_csv.write(\"1.,, 0\\n\")\n",
        "test_csv.write(\"4., 5. , 1\\n\")\n",
        "test_csv.write(\"7., 8. , 0\\n\")\n",
        "test_csv.close()\n",
        "\n",
        "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
        "filename = tf.placeholder(tf.string)\n",
        "enqueue_filename = filename_queue.enqueue([filename])\n",
        "close_filename_queue = filename_queue.close()\n",
        "\n",
        "reader = tf.TextLineReader(skip_header_lines=1)\n",
        "key, value = reader.read(filename_queue)\n",
        "\n",
        "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
        "features = tf.stack([x1, x2])\n",
        "\n",
        "instance_queue = tf.RandomShuffleQueue(\n",
        "    capacity=10, min_after_dequeue=2,\n",
        "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
        "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
        "enqueue_instance = instance_queue.enqueue([features, target])\n",
        "close_instance_queue = instance_queue.close()\n",
        "\n",
        "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
        "    sess.run(close_filename_queue)\n",
        "    try:\n",
        "        while True:\n",
        "            sess.run(enqueue_instance)\n",
        "    except tf.errors.OutOfRangeError as ex:\n",
        "        print(\"No more files to read\")\n",
        "    sess.run(close_instance_queue)\n",
        "    try:\n",
        "        while True:\n",
        "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
        "    except tf.errors.OutOfRangeError as ex:\n",
        "        print(\"No more training instances\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 15:31:35.184544 140185111480192 deprecation.py:323] From <ipython-input-11-80d0fc178d22>:15: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No more files to read\n",
            "[array([[ 4.,  5.],\n",
            "       [ 1., -1.]], dtype=float32), array([1, 0], dtype=int32)]\n",
            "[array([[7., 8.]], dtype=float32), array([0], dtype=int32)]\n",
            "No more training instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLxWDg5_NjQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8cc3992e-b2ce-4cd3-8238-4d4a68385593"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
        "filename = tf.placeholder(tf.string)\n",
        "enqueue_filename = filename_queue.enqueue([filename])\n",
        "close_filename_queue = filename_queue.close()\n",
        "\n",
        "reader = tf.TextLineReader(skip_header_lines=1)\n",
        "key, value = reader.read(filename_queue)\n",
        "\n",
        "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
        "features = tf.stack([x1, x2])\n",
        "\n",
        "instance_queue = tf.RandomShuffleQueue(\n",
        "    capacity=10, min_after_dequeue=2,\n",
        "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
        "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
        "enqueue_instance = instance_queue.enqueue([features, target])\n",
        "close_instance_queue = instance_queue.close()\n",
        "\n",
        "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
        "\n",
        "n_threads = 5\n",
        "queue_runner = tf.train.QueueRunner(instance_queue, [enqueue_instance] * n_threads)\n",
        "coord = tf.train.Coordinator()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
        "    sess.run(close_filename_queue)\n",
        "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
        "    try:\n",
        "        while True:\n",
        "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
        "    except tf.errors.OutOfRangeError as ex:\n",
        "        print(\"No more training instances\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 15:32:05.674272 140185111480192 deprecation.py:323] From <ipython-input-12-0b9894c3c9bb>:24: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[array([[ 4.,  5.],\n",
            "       [ 1., -1.]], dtype=float32), array([1, 0], dtype=int32)]\n",
            "[array([[7., 8.]], dtype=float32), array([0], dtype=int32)]\n",
            "No more training instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq7vioZ8Nqtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2b08077f-8839-4192-b1a9-20fb6c1e67bf"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "def read_and_push_instance(filename_queue, instance_queue):\n",
        "    reader = tf.TextLineReader(skip_header_lines=1)\n",
        "    key, value = reader.read(filename_queue)\n",
        "    x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
        "    features = tf.stack([x1, x2])\n",
        "    enqueue_instance = instance_queue.enqueue([features, target])\n",
        "    return enqueue_instance\n",
        "\n",
        "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
        "filename = tf.placeholder(tf.string)\n",
        "enqueue_filename = filename_queue.enqueue([filename])\n",
        "close_filename_queue = filename_queue.close()\n",
        "\n",
        "instance_queue = tf.RandomShuffleQueue(\n",
        "    capacity=10, min_after_dequeue=2,\n",
        "    dtypes=[tf.float32, tf.int32], shapes=[[2],[]],\n",
        "    name=\"instance_q\", shared_name=\"shared_instance_q\")\n",
        "\n",
        "minibatch_instances, minibatch_targets = instance_queue.dequeue_up_to(2)\n",
        "\n",
        "read_and_enqueue_ops = [read_and_push_instance(filename_queue, instance_queue) for i in range(5)]\n",
        "queue_runner = tf.train.QueueRunner(instance_queue, read_and_enqueue_ops)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(enqueue_filename, feed_dict={filename: \"my_test.csv\"})\n",
        "    sess.run(close_filename_queue)\n",
        "    coord = tf.train.Coordinator()\n",
        "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
        "    try:\n",
        "        while True:\n",
        "            print(sess.run([minibatch_instances, minibatch_targets]))\n",
        "    except tf.errors.OutOfRangeError as ex:\n",
        "        print(\"No more training instances\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[ 4.,  5.],\n",
            "       [ 1., -1.]], dtype=float32), array([1, 0], dtype=int32)]\n",
            "[array([[7., 8.]], dtype=float32), array([0], dtype=int32)]\n",
            "No more training instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU4Z89jpNywk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e8183ca4-e5ee-45eb-8534-6f4575794a05"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "q = tf.FIFOQueue(capacity=10, dtypes=[tf.float32], shapes=[()])\n",
        "v = tf.placeholder(tf.float32)\n",
        "enqueue = q.enqueue([v])\n",
        "dequeue = q.dequeue()\n",
        "output = dequeue + 1\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "config.operation_timeout_in_ms = 1000\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(enqueue, feed_dict={v: 1.0})\n",
        "    sess.run(enqueue, feed_dict={v: 2.0})\n",
        "    sess.run(enqueue, feed_dict={v: 3.0})\n",
        "    print(sess.run(output))\n",
        "    print(sess.run(output, feed_dict={dequeue: 5}))\n",
        "    print(sess.run(output))\n",
        "    print(sess.run(output))\n",
        "    try:\n",
        "        print(sess.run(output))\n",
        "    except tf.errors.DeadlineExceededError as ex:\n",
        "        print(\"Timed out while dequeuing\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0\n",
            "6.0\n",
            "3.0\n",
            "4.0\n",
            "Timed out while dequeuing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd-LN6O_N1Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}