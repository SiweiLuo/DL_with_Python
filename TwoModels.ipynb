{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwoModels.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiweiLuo/DL_with_Python/blob/master/TwoModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "idzcX64hSd9G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NOTE: define the following variables\n",
        "#       top_model_weights_path\n",
        "#       num_classes\n",
        "#       dense_layer_1 = 4096\n",
        "#       dense_layer_2 = 4096\n",
        "\n",
        "vgg16 = applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3))\n",
        "\n",
        "# Inspect the model\n",
        "vgg16.summary()\n",
        "\n",
        "# This shape has to match the last layer in VGG16 (without top)\n",
        "dense_input  = Input(shape=(7, 7, 512))\n",
        "dense_output = Flatten(name='flatten')(dense_input)\n",
        "dense_output = Dense(dense_layer_1, activation='relu', name='fc1')(dense_output)\n",
        "dense_output = Dense(dense_layer_2, activation='relu', name='fc2')(dense_output)\n",
        "dense_output = Dense(num_classes, activation='softmax', name='predictions')(dense_output)\n",
        "\n",
        "top_model = Model(inputs=dense_input, outputs=dense_output, name='top_model')\n",
        "\n",
        "# from: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "block5_pool = vgg16.get_layer('block5_pool').output\n",
        "\n",
        "# Now combine the two models\n",
        "full_output = top_model(block5_pool)\n",
        "full_model  = Model(inputs=vgg16.input, outputs=full_output)\n",
        "\n",
        "# set the first 15 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "# WARNING: this may not be applicable for Inception V3\n",
        "for layer in full_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Verify things look as expected\n",
        "full_model.summary()\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "full_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=optimizers.SGD(lr=5e-5, momentum=0.9),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Train the model..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}