{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_preprocess.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiweiLuo/DL_with_Python/blob/master/CV_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FjTBBz5fu7Eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import string \n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing import text, sequence\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#import StringIO\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjCNI9ZOu_XQ",
        "colab_type": "code",
        "outputId": "91c81bf4-acd2-45b4-89a1-de935e62a2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rx5h2JUGvBAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv(r'/content/gdrive/My Drive/Colab Notebooks/CareerVillage/questions.csv')\n",
        "#print('questions = ',questions)\n",
        "answers = pd.read_csv(r'/content/gdrive/My Drive/Colab Notebooks/CareerVillage/answers.csv')\n",
        "#print('answers = ',answers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4Vi0WO4vDBH",
        "colab_type": "code",
        "outputId": "5039632c-ab21-4a51-fdf9-5327ca44ef71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "answers_body = answers.answers_body\n",
        "questions_body = questions.questions_body\n",
        "#answers_body = list(answers_body)\n",
        "#len(answers_body)\n",
        "#len(answers_body[2])\n",
        "len(questions_body)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "YqyUJmDrvFoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "    '''\n",
        "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
        "    '''\n",
        "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&' + '\\n' \n",
        "    def clean_special_chars(text, punct):\n",
        "        for p in punct:\n",
        "            text = text.replace(p, ' ')\n",
        "        return text\n",
        "\n",
        "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LEiKXc_PvLQ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = preprocess(answers_body)\n",
        "q_shape = preprocess(questions_body)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fr8GJW1VvNJ9",
        "colab_type": "code",
        "outputId": "c9d0b22a-9add-43c1-86ee-c416694a8c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "HB-L9dHpvm7c",
        "colab_type": "code",
        "outputId": "6b4cde40-5660-4f15-ddb6-312d388e4b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "XhvURbe7vOk3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(x_train)+list(q_shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhmZ9YTdvaXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "q_shape = tokenizer.texts_to_sequences(q_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jmelhge5vdeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LPlrZ26uZlnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question_len = 40 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0LdPN_fvfgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = sequence.pad_sequences(x_train,maxlen=500)\n",
        "q_shape = sequence.pad_sequences(q_shape,maxlen=question_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyUYJe9Ev26K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3vZPnzWYS4c",
        "colab_type": "code",
        "outputId": "b821f7fd-3ef9-43c1-d0a1-677e14c87c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "q_shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,   25,   11,    5, 2449,  302,   25,   11,\n",
              "          5, 2449,  302,  800,   29,  653, 2665], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "q9FiAfiVv4P7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras import layers\n",
        "from keras import backend as K \n",
        "from keras.models import Model\n",
        "import numpy as np \n",
        "from keras import Input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sf1gn_HHYAiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size =16\n",
        "latent_dim = 2 \n",
        "question_shape = (40,1)\n",
        "input_qus = keras.Input(shape=question_shape)\n",
        "x = layers.LSTM(32,return_sequences=True,input_shape=(40,))(input_qus)\n",
        "x = layers.LSTM((32))(x)\n",
        "#x = layers.LSTM((32))(x)\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "\n",
        "#x = layers.Flatten()(x)\n",
        "x = layers.Dense(32,activation='softmax')(x)\n",
        "\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "que_encoder = Model(input_qus,z_mean)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Py_bupLs016",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer_shape = (40,1)\n",
        "input_ans = keras.Input(shape=answer_shape)\n",
        "x = layers.LSTM(64,return_sequences=True,input_shape=(40,))(input_ans)\n",
        "x = layers.LSTM((64))(x)\n",
        "#x = layers.LSTM((64))(x)\n",
        "x = layers.Dense(32,activation='softmax')(x)\n",
        "\n",
        "z_mean_ans = layers.Dense(latent_dim)(x)\n",
        "z_log_var_ans = layers.Dense(latent_dim)(x)\n",
        "\n",
        "ans_encoder = Model(input_ans,z_mean_ans)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N27af_0OymrJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#concatenated = layers.concatenate([z_mean,z_mean_ans],axis=-1)\n",
        "concatenated = (z_mean-z_mean_ans)**2\n",
        "combined = layers.Dense(1,input_shape = (1,))(concatenated)\n",
        "\n",
        "correlation = Model([input_qus,input_ans])\n",
        "\n",
        "correlation.compile(optimizer = 'rmsprop',loss=None,metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpU4fOHsIMzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder = Sequential()\n",
        "\n",
        "decoder.Add(layers.Dense(32,activation='relu',input_shape=(2,)))\n",
        "decoder.Add(layers.Dense(32,activation='relu'))\n",
        "decoder.Add(layers.Dense(32,activation='softmax'))\n",
        "\n",
        "decoder.compile(optimizer='rmsprop',loss='categroical_crossentropy',metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3rvYiMVJiOY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xbuOPsgWZqdF",
        "colab_type": "code",
        "outputId": "7c214d6e-340d-4930-f9cc-c5af9a7cf536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "shape_before_flattening "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "_iVCmA8ycIo3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0.,stddev=1.)\n",
        "  return z_mean + K.exp(z_log_var)*epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean,z_log_var])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C0Fgj6FVgBoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
        "                activation='relu')(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "#x = layers.LSTM(32)(x)\n",
        "#x = layers.Dense(32,activation='softmax')(x)\n",
        "\n",
        "#decoder = Model(decoder_input,x)\n",
        "#z_decoded = decoder(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbPWSb7thjiA",
        "colab_type": "code",
        "outputId": "507bfbc1-69f3-4b64-84f7-ebe8d92e7b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(32)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "dSCkeiDAdQAM",
        "colab_type": "code",
        "outputId": "418fabd8-a5f1-4b37-87ae-aad74c0f6b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "class CustomVariationLayer(keras.layers.Layer):\n",
        "  def vae_loss(self,x,z_decoded):\n",
        "    #x = K.flatten(x)\n",
        "    #z_decoded = K.f\n",
        "    z_decoded = z_decoded\n",
        "    xent_loss = keras.metrics.binary_crossentropy(x,z_decoded)\n",
        "    kl_loss = -5e-4 * K.mean(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)\n",
        "    return K.mean(xent_loss+kl_loss)\n",
        "  \n",
        "  def call(self,inputs):\n",
        "    x = inputs[0]\n",
        "    z_decoded = inputs[1]\n",
        "    loss = self.vae_loss(x,z_decoded)\n",
        "    self.add_loss(loss,inputs=inputs)\n",
        "    return x \n",
        "  \n",
        "y = CustomVariationLayer()([input_qus,z_decoded])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c229e77d8f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomVariationLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_qus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_decoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'z_decoded' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "K5e8kMrXfsmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vae = Model(input_qus,y)\n",
        "\n",
        "vae.compile(optimizer='rmsprop',loss=None)\n",
        "vae.summary()\n",
        "\n",
        "vae.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}